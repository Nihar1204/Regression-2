{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Assignment-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# R-squared is a way to find model accuracy in linear regression.\n",
    "# Formula:\n",
    "# 1 - (Σ(yi - y_pred)^2 / Σ(yi - y_mean)^2) , where i [1 to n]\n",
    "\n",
    "# It represent the accuracy of the linear regression model. And the value of R-squared ranges from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Adjusted R-squared is another way to find model's accuracy. But it is slightly different than the R-squared.\n",
    "# Adjusted R-squared is a bit accurate than the R-squared because it exclude those features who are contributing\n",
    "# significantly neglezable or zero values in the model performance.\n",
    "\n",
    "# Formula:\n",
    "# 1 - ((1-R^2) (N-1)/N-P-1)\n",
    "# R: R-squared value\n",
    "# N: Number of data points\n",
    "# P: Number of independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# When there are some less significant features available in the dataset it is more appropriate to use \n",
    "# adjusted R-squared instead of R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "# calculated, and what do they represent?\n",
    "\n",
    "# Ans\n",
    "\n",
    "# RMSE, MSE, and MAE represent different types of cost functions in regression.\n",
    "# RMSE: Root Mean Squared Error\n",
    "# Formula: sqrt(1/n * Σ(yi-y_pred)^2)\n",
    "\n",
    "# MSE: Mean Squared Error\n",
    "# Formula: 1/n * Σ(yi-y_pred)^2\n",
    "\n",
    "# MAE: Mean Absolute Error\n",
    "# Formula: 1/n * Σ|yi-y_pred|\n",
    "\n",
    "# Where i = 1 to n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in \n",
    "# regression analysis.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# RMSE\n",
    "# Advantages:\n",
    "# Equation is differentiable.\n",
    "# It is in the same unit.\n",
    "\n",
    "# Disadvantages:\n",
    "# Not robust for outliers.\n",
    "\n",
    "\n",
    "# MSE\n",
    "# Advantages:\n",
    "# Equation is differentiable.\n",
    "# It has only one local or global minima.\n",
    "\n",
    "# Disadvantages:\n",
    "# Not robust for outliers.\n",
    "# It is not in the same unit.\n",
    "\n",
    "# MAE\n",
    "# Advantages:\n",
    "# Robust for outliers.\n",
    "# It is in the same unit.\n",
    "\n",
    "# Disadvantages:\n",
    "# Convergence usually takes more time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "# it more appropriate to use?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Lasso regularization or L1 regularization is a technique of linear regression to improve model's performance\n",
    "# and accuracy.\n",
    "\n",
    "# Cost function: MSE + λ(Σ|θi|), where i = 1 to n\n",
    "\n",
    "# Lasso regularization and Ridge regularization both are used to improve model's accuracy still they have some \n",
    "# different use cases:\n",
    "# Ridge regularization is primarily used to tackle overfitting of the model by penalizing the Cost Function.\n",
    "# Where Lasso regularization is used in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "# example to illustrate.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Regularized linear models penalize the cost function by adding some values. So the error will not be zero.\n",
    "\n",
    "# Example:\n",
    "# Let say we have a dataset and we trained our model, and the training model's accuracy is 100%. Which indicates \n",
    "# our error is 0. So if we test our model with some unseen data the model's accuracy will be decreased. It leads\n",
    "# to model overfitting. To tackle these scenarios we use regularized linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "# choice for regression analysis.\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# 1 Sensitivity to Feature Scaling:\n",
    "# Regularization is applied to feature weights, making models sensitive to different feature scales.\n",
    "\n",
    "# 2 Feature Selection Issues (Lasso):\n",
    "# Lasso (L1 regularization) can shrink some coefficients to exactly zero, leading to feature selection.\n",
    "# Problem: If features are highly correlated, Lasso may arbitrarily choose one while ignoring the others, leading \n",
    "# to unstable feature selection.\n",
    "\n",
    "# 3 Poor Performance on Small Datasets:\n",
    "# Regularization reduces model complexity, which may be unnecessary for small datasets with fewer parameters.\n",
    "# Problem: Ridge or Lasso can underfit when the dataset is small and does not have multicollinearity issues.\n",
    "\n",
    "# 4 Difficult Hyperparameter Tuning:\n",
    "# The regularization strength (λ) must be fine-tuned using cross-validation.\n",
    "# Problem: Choosing the wrong value of λ can lead to underfitting (too large λ) or overfitting (too small λ).\n",
    "\n",
    "# 5 Assumption of Linearity:\n",
    "# Regularized models still assume a linear relationship between features and target variables.\n",
    "# Problem: If the true relationship is nonlinear, these models fail to capture complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "# Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "# performer, and why? Are there any limitations to your choice of metric?\n",
    "\n",
    "\n",
    "# Ans:\n",
    "\n",
    "\n",
    "# Comparing the Models\n",
    "# Since Model A has an RMSE of 10 and Model B has an MAE of 8, we cannot directly compare them without additional \n",
    "# context because they measure different aspects of error.\n",
    "\n",
    "# If we care about large errors (outliers) and want a model that minimizes large deviations, we should prefer the model \n",
    "# with the lower RMSE (Model A).\n",
    "# If we want a model that performs consistently well on average, we should prefer the model \n",
    "# with the lower MAE (Model B).\n",
    "\n",
    "# Limitations of Choosing a Metric\n",
    "# RMSE is higher than MAE by design (since squared errors increase the magnitude).\n",
    "# If outliers exist, RMSE will be much larger than MAE.\n",
    "# If errors are uniformly distributed, RMSE and MAE will be closer in value.\n",
    "\n",
    "\n",
    "# Final Decision\n",
    "# If the goal is robustness (minimizing large errors), choose Model A (lower RMSE).\n",
    "# If the goal is overall consistency (minimizing typical error), choose Model B (lower MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "# regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "# uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "# better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "# method?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Comparing Ridge (L2) and Lasso (L1) Regularization Models\n",
    "# We have two models:\n",
    "\n",
    "# Model A: Ridge Regression (L2 regularization) with λ = 0.1\n",
    "# Model B: Lasso Regression (L1 regularization) with λ = 0.5\n",
    "\n",
    "# Evaluating Performance: Which Model is Better?\n",
    "\n",
    "# If all features contribute to prediction (no irrelevant features) → Ridge (Model A) is better\n",
    "# If only a few features matter (some irrelevant features) → Lasso (Model B) is better\n",
    "# If multicollinearity is present → Ridge is preferred\n",
    "# If feature selection is needed → Lasso is preferred\n",
    "\n",
    "# Trade-offs and Limitations:\n",
    "\n",
    "# Ridge (L2) Trade-offs:\n",
    "# Works well when all features contribute\n",
    "# Handles multicollinearity better\n",
    "# Does not perform feature selection\n",
    "\n",
    "# Lasso (L1) Trade-offs:\n",
    "# Performs automatic feature selection\n",
    "# Helps when we suspect some features are irrelevant\n",
    "# If features are highly correlated, it picks only one (not ideal for multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
